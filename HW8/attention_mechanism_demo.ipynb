{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"attention_mechanism_demo.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"EB0ipHig9gOm","colab_type":"text"},"source":["# Attention Mechanism Demo on Keras: Machine Translation Example (Many-to-Many, encoder-decoder)\n","\n","In this demo, we will show you how to create a machine translator using Keras. This demo is inspired by Andrew Ng's deeplearning.ai course on sequence models. (Programming Assignment: Neural Machine Translation with Attention)    In this demo, we create a machine translator to translate dates in various formats  into dates in an ISO format. "]},{"cell_type":"code","metadata":{"id":"3_clL4w89gOt","colab_type":"code","outputId":"0a9a50a7-193a-45f1-e84f-0a818ae786f2","executionInfo":{"status":"ok","timestamp":1584637281072,"user_tz":-420,"elapsed":2983,"user":{"displayName":"Can Udomcharoenchaikit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIB8FkrZmMx76pFQKcawrImVzazmJLi7rbH86KvA=s64","userId":"04089022953377520706"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["%matplotlib inline\n","\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","\n","import tensorflow as tf\n","print(tf.__version__)\n","\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n","from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import load_model, Model\n","import tensorflow.keras.backend as K\n","import numpy as np\n","\n","import random\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n","2.1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cEyHEfFt9gO9","colab_type":"text"},"source":["## Generate Dataset\n","We generate a toy dataset using datetime library.  A target output only comes in one format (iso format), while there are three different date format for an input."]},{"cell_type":"code","metadata":{"id":"MWRgqvwY9gO_","colab_type":"code","colab":{}},"source":["#Generating a toy dataset\n","import datetime\n","base = datetime.datetime.today()\n","base = datetime.date(base.year, base.month, base.day)\n","date_list = [base - datetime.timedelta(days=x) for x in range(0, 15000)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KrNHzgFy9gPI","colab_type":"code","outputId":"bdd38ea6-ace6-4193-efc3-f5084800861c","executionInfo":{"status":"ok","timestamp":1584637281076,"user_tz":-420,"elapsed":2971,"user":{"displayName":"Can Udomcharoenchaikit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIB8FkrZmMx76pFQKcawrImVzazmJLi7rbH86KvA=s64","userId":"04089022953377520706"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["target_date_list = [date.isoformat() for date in date_list] \n","print(target_date_list[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-03-19\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GT7V4FJL9gPR","colab_type":"code","colab":{}},"source":["from random import randint\n","random.seed(42)\n","input_date_list = list()\n","for date in date_list:\n","    random_num = randint(0, 2)\n","    if random_num == 0:\n","        input_date_list.append(date.strftime(\"%d/%m/%y\"))#\"11/03/02\"\n","    elif random_num == 1:\n","        input_date_list.append(date.strftime(\"%A %d %B %Y\")) #\"Monday 11 March 2002\"\n","    elif random_num == 2: \n","        input_date_list.append(date.strftime(\"%d %B %Y\")) #\"11 March 2002\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"isfXKy2y9gPZ","colab_type":"code","outputId":"15eacee4-0e30-418a-dfbe-9882a4dc0e4d","executionInfo":{"status":"ok","timestamp":1584637281080,"user_tz":-420,"elapsed":2964,"user":{"displayName":"Can Udomcharoenchaikit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIB8FkrZmMx76pFQKcawrImVzazmJLi7rbH86KvA=s64","userId":"04089022953377520706"}},"colab":{"base_uri":"https://localhost:8080/","height":191}},"source":["for input_sample, target_sample in zip(input_date_list[0:10],target_date_list[0:10]):\n","    print(input_sample,target_sample)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["19 March 2020 2020-03-19\n","18/03/20 2020-03-18\n","17/03/20 2020-03-17\n","16 March 2020 2020-03-16\n","Sunday 15 March 2020 2020-03-15\n","14/03/20 2020-03-14\n","13/03/20 2020-03-13\n","12/03/20 2020-03-12\n","11 March 2020 2020-03-11\n","10/03/20 2020-03-10\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7KndjKsS9gPg","colab_type":"code","outputId":"34f38dc4-a28b-4bbb-e61b-7fa41d69a2fe","executionInfo":{"status":"ok","timestamp":1584637285454,"user_tz":-420,"elapsed":1095,"user":{"displayName":"Can Udomcharoenchaikit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIB8FkrZmMx76pFQKcawrImVzazmJLi7rbH86KvA=s64","userId":"04089022953377520706"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Preprocessing\n","input_chars = list(set(''.join(input_date_list)))\n","output_chars = list(set(''.join(target_date_list)))\n","# +1 for padding\n","data_size, vocab_size = len(input_date_list), len(input_chars)+1 \n","output_vocab_size = len(output_chars)+1\n","print('There are %d lines and %d unique characters in your input data.' % (data_size, vocab_size))\n","maxlen = len( max(input_date_list, key=len)) #max input length"],"execution_count":0,"outputs":[{"output_type":"stream","text":["There are 15000 lines and 42 unique characters in your input data.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3K-0kaUH9gPn","colab_type":"code","outputId":"8de08e5e-916a-40fa-8c7c-1f3455805c62","executionInfo":{"status":"ok","timestamp":1584637285456,"user_tz":-420,"elapsed":563,"user":{"displayName":"Can Udomcharoenchaikit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIB8FkrZmMx76pFQKcawrImVzazmJLi7rbH86KvA=s64","userId":"04089022953377520706"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"Max input length:\", maxlen)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Max input length: 27\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dCSo8cR29gPu","colab_type":"code","outputId":"914dcb08-1464-441b-d2c8-a3c53c242143","executionInfo":{"status":"ok","timestamp":1584637287590,"user_tz":-420,"elapsed":736,"user":{"displayName":"Can Udomcharoenchaikit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIB8FkrZmMx76pFQKcawrImVzazmJLi7rbH86KvA=s64","userId":"04089022953377520706"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["sorted_chars= sorted(input_chars)\n","sorted_output_chars= sorted(output_chars)\n","sorted_chars.insert(0,\"<PAD>\")#PADDING for input\n","sorted_output_chars.insert(0,\"<PAD>\")#PADDING for output\n","#Input\n","char_to_ix = { ch:i for i,ch in enumerate(sorted_chars) }\n","ix_to_char = { i:ch for i,ch in enumerate(sorted_chars) } #reverse dictionary\n","#Output\n","output_char_to_ix = { ch:i for i,ch in enumerate(sorted_output_chars) }\n","ix_to_output_char = { i:ch for i,ch in enumerate(sorted_output_chars) } #reverse dictionary\n","\n","print(ix_to_char)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{0: '<PAD>', 1: ' ', 2: '/', 3: '0', 4: '1', 5: '2', 6: '3', 7: '4', 8: '5', 9: '6', 10: '7', 11: '8', 12: '9', 13: 'A', 14: 'D', 15: 'F', 16: 'J', 17: 'M', 18: 'N', 19: 'O', 20: 'S', 21: 'T', 22: 'W', 23: 'a', 24: 'b', 25: 'c', 26: 'd', 27: 'e', 28: 'g', 29: 'h', 30: 'i', 31: 'l', 32: 'm', 33: 'n', 34: 'o', 35: 'p', 36: 'r', 37: 's', 38: 't', 39: 'u', 40: 'v', 41: 'y'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8Q0XsxhL9gP2","colab_type":"code","colab":{}},"source":["m=15000\n","Tx=maxlen\n","Ty=10"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PvKOfVnc9gP-","colab_type":"code","outputId":"5e33a234-3973-49f6-b1c6-540a9ab4b647","executionInfo":{"status":"ok","timestamp":1584637289825,"user_tz":-420,"elapsed":1144,"user":{"displayName":"Can Udomcharoenchaikit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIB8FkrZmMx76pFQKcawrImVzazmJLi7rbH86KvA=s64","userId":"04089022953377520706"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X = []\n","for line in input_date_list:\n","    temp=[]\n","    for char in line:\n","        temp.append(char_to_ix[char])\n","    X.append(temp)\n","Y = []\n","for line in target_date_list:\n","    temp=[]\n","    for char in line:\n","        temp.append(output_char_to_ix[char])\n","    Y.append(temp)    \n","\n","X = pad_sequences(X,maxlen=maxlen)\n","# Y = pad_sequences(Y,maxlen=10)\n","\n","X= to_categorical(X,vocab_size)\n","X=X.reshape(data_size,maxlen ,vocab_size)\n","\n","Y= to_categorical(Y,output_vocab_size)\n","Y=Y.reshape(data_size,10 ,output_vocab_size)\n","print(X.shape,Y.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(15000, 27, 42) (15000, 10, 12)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UFYhwzdj9gQG","colab_type":"text"},"source":["# Attention Mechanism\n","![attn_mech](https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/images/attn_mech.png)"]},{"cell_type":"code","metadata":{"id":"76X7VMpD9gQI","colab_type":"code","colab":{}},"source":["from tensorflow.keras.activations import softmax\n","def softMaxAxis1(x):\n","    return softmax(x,axis=1)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FhngrOGI9gQO","colab_type":"code","colab":{}},"source":["#These are global variables (shared layers)\n","repeator = RepeatVector(Tx)\n","concatenator = Concatenate(axis=-1)\n","#Attention function###\n","fattn_1 = Dense(10, activation = \"tanh\")\n","fattn_2 = Dense(1, activation = \"relu\")\n","###\n","activator = Activation(softMaxAxis1, name='attention_scores') \n","dotor = Dot(axes = 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rc6wgVVq9gQU","colab_type":"code","colab":{}},"source":["def one_step_attention(a, s_prev):\n","\n","    # Repeat the decoder hidden state to concat with encoder hidden states\n","    s_prev = repeator(s_prev)\n","    concat = concatenator([a,s_prev])\n","    # attention function\n","    e = fattn_1(concat)\n","    energies =fattn_2(e)\n","    # calculate attention_scores (softmax)\n","    attention_scores = activator(energies)\n","    #calculate a context vector\n","    context = dotor([attention_scores,a])\n","\n","    return context"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qv475_JS9gQY","colab_type":"text"},"source":["# The model\n","![rnn_model](https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/images/rnn_date.png)"]},{"cell_type":"code","metadata":{"id":"duCZrcle9gQa","colab_type":"code","colab":{}},"source":["n_h = 32 #hidden dimensions for encoder \n","n_s = 64 #hidden dimensions for decoder\n","encoder_LSTM =  Bidirectional(LSTM(n_h, return_sequences=True),input_shape=(-1, Tx, n_h*2))\n","decoder_LSTM_cell = LSTM(n_s, return_state = True) #decoder_LSTM_cell\n","output_layer = Dense(output_vocab_size, activation=\"softmax\") #softmax output layer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uwYrnDV79gQf","colab_type":"code","colab":{}},"source":["def model(Tx, Ty, n_h, n_s, vocab_size, machine_vocab_size):\n","    \"\"\"\n","    Arguments:\n","    Tx -- length of the input sequence\n","    Ty -- length of the output sequence\n","    n_h -- hidden state size of the Bi-LSTM\n","    n_s -- hidden state size of the post-attention LSTM\n","    vocab_size -- size of the input vocab\n","    output_vocab_size -- size of the output vocab\n","\n","    Returns:\n","    model -- Keras model instance\n","    \"\"\"\n","    \n","    # Define the input of your model\n","    X = Input(shape=(Tx, vocab_size))\n","    # Define hidden state and cell state for decoder_LSTM_Cell\n","    s0 = Input(shape=(n_s,), name='s0')\n","    c0 = Input(shape=(n_s,), name='c0')\n","    s = s0\n","    c = c0\n","    \n","    # Initialize empty list of outputs\n","    outputs = list()\n","\n","    #Encoder Bi-LSTM\n","    # h = Bidirectional(LSTM(n_h, return_sequences=True),input_shape=(-1, Tx, n_h*2))(X)\n","    h = encoder_LSTM(X)\n","    #Iterate for Ty steps (Decoding)\n","    for t in range(Ty):\n","    \n","        #Perform one step of the attention mechanism to calculate the context vector at timestep t\n","        context = one_step_attention(h, s)\n","       \n","        # Feed the context vector to the decoder LSTM cell\n","        s, _, c = decoder_LSTM_cell(context,initial_state=[s,c])\n","           \n","        # Pass the decoder hidden output to the output layer (softmax)\n","        out = output_layer(s)\n","        \n","        # Append an output list with the current output\n","        outputs.append(out)\n","    \n","    #Create model instance\n","    model = Model(inputs=[X,s0,c0],outputs=outputs)\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-7k1D9DP9gQj","colab_type":"code","colab":{}},"source":["model = model(Tx, Ty, n_h, n_s, vocab_size, output_vocab_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3lw3lcYN9gQp","colab_type":"code","outputId":"ae4524a2-e264-4d99-a1cc-dc49cc7aebfe","executionInfo":{"status":"ok","timestamp":1584637308785,"user_tz":-420,"elapsed":9765,"user":{"displayName":"Can Udomcharoenchaikit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIB8FkrZmMx76pFQKcawrImVzazmJLi7rbH86KvA=s64","userId":"04089022953377520706"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 27, 42)]     0                                            \n","__________________________________________________________________________________________________\n","s0 (InputLayer)                 [(None, 64)]         0                                            \n","__________________________________________________________________________________________________\n","bidirectional (Bidirectional)   (None, 27, 64)       19200       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","repeat_vector (RepeatVector)    (None, 27, 64)       0           s0[0][0]                         \n","                                                                 lstm_1[0][0]                     \n","                                                                 lstm_1[1][0]                     \n","                                                                 lstm_1[2][0]                     \n","                                                                 lstm_1[3][0]                     \n","                                                                 lstm_1[4][0]                     \n","                                                                 lstm_1[5][0]                     \n","                                                                 lstm_1[6][0]                     \n","                                                                 lstm_1[7][0]                     \n","                                                                 lstm_1[8][0]                     \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 27, 128)      0           bidirectional[0][0]              \n","                                                                 repeat_vector[0][0]              \n","                                                                 bidirectional[0][0]              \n","                                                                 repeat_vector[1][0]              \n","                                                                 bidirectional[0][0]              \n","                                                                 repeat_vector[2][0]              \n","                                                                 bidirectional[0][0]              \n","                                                                 repeat_vector[3][0]              \n","                                                                 bidirectional[0][0]              \n","                                                                 repeat_vector[4][0]              \n","                                                                 bidirectional[0][0]              \n","                                                                 repeat_vector[5][0]              \n","                                                                 bidirectional[0][0]              \n","                                                                 repeat_vector[6][0]              \n","                                                                 bidirectional[0][0]              \n","                                                                 repeat_vector[7][0]              \n","                                                                 bidirectional[0][0]              \n","                                                                 repeat_vector[8][0]              \n","                                                                 bidirectional[0][0]              \n","                                                                 repeat_vector[9][0]              \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 27, 10)       1290        concatenate[0][0]                \n","                                                                 concatenate[1][0]                \n","                                                                 concatenate[2][0]                \n","                                                                 concatenate[3][0]                \n","                                                                 concatenate[4][0]                \n","                                                                 concatenate[5][0]                \n","                                                                 concatenate[6][0]                \n","                                                                 concatenate[7][0]                \n","                                                                 concatenate[8][0]                \n","                                                                 concatenate[9][0]                \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 27, 1)        11          dense[0][0]                      \n","                                                                 dense[1][0]                      \n","                                                                 dense[2][0]                      \n","                                                                 dense[3][0]                      \n","                                                                 dense[4][0]                      \n","                                                                 dense[5][0]                      \n","                                                                 dense[6][0]                      \n","                                                                 dense[7][0]                      \n","                                                                 dense[8][0]                      \n","                                                                 dense[9][0]                      \n","__________________________________________________________________________________________________\n","attention_scores (Activation)   (None, 27, 1)        0           dense_1[0][0]                    \n","                                                                 dense_1[1][0]                    \n","                                                                 dense_1[2][0]                    \n","                                                                 dense_1[3][0]                    \n","                                                                 dense_1[4][0]                    \n","                                                                 dense_1[5][0]                    \n","                                                                 dense_1[6][0]                    \n","                                                                 dense_1[7][0]                    \n","                                                                 dense_1[8][0]                    \n","                                                                 dense_1[9][0]                    \n","__________________________________________________________________________________________________\n","dot (Dot)                       (None, 1, 64)        0           attention_scores[0][0]           \n","                                                                 bidirectional[0][0]              \n","                                                                 attention_scores[1][0]           \n","                                                                 bidirectional[0][0]              \n","                                                                 attention_scores[2][0]           \n","                                                                 bidirectional[0][0]              \n","                                                                 attention_scores[3][0]           \n","                                                                 bidirectional[0][0]              \n","                                                                 attention_scores[4][0]           \n","                                                                 bidirectional[0][0]              \n","                                                                 attention_scores[5][0]           \n","                                                                 bidirectional[0][0]              \n","                                                                 attention_scores[6][0]           \n","                                                                 bidirectional[0][0]              \n","                                                                 attention_scores[7][0]           \n","                                                                 bidirectional[0][0]              \n","                                                                 attention_scores[8][0]           \n","                                                                 bidirectional[0][0]              \n","                                                                 attention_scores[9][0]           \n","                                                                 bidirectional[0][0]              \n","__________________________________________________________________________________________________\n","c0 (InputLayer)                 [(None, 64)]         0                                            \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   [(None, 64), (None,  33024       dot[0][0]                        \n","                                                                 s0[0][0]                         \n","                                                                 c0[0][0]                         \n","                                                                 dot[1][0]                        \n","                                                                 lstm_1[0][0]                     \n","                                                                 lstm_1[0][2]                     \n","                                                                 dot[2][0]                        \n","                                                                 lstm_1[1][0]                     \n","                                                                 lstm_1[1][2]                     \n","                                                                 dot[3][0]                        \n","                                                                 lstm_1[2][0]                     \n","                                                                 lstm_1[2][2]                     \n","                                                                 dot[4][0]                        \n","                                                                 lstm_1[3][0]                     \n","                                                                 lstm_1[3][2]                     \n","                                                                 dot[5][0]                        \n","                                                                 lstm_1[4][0]                     \n","                                                                 lstm_1[4][2]                     \n","                                                                 dot[6][0]                        \n","                                                                 lstm_1[5][0]                     \n","                                                                 lstm_1[5][2]                     \n","                                                                 dot[7][0]                        \n","                                                                 lstm_1[6][0]                     \n","                                                                 lstm_1[6][2]                     \n","                                                                 dot[8][0]                        \n","                                                                 lstm_1[7][0]                     \n","                                                                 lstm_1[7][2]                     \n","                                                                 dot[9][0]                        \n","                                                                 lstm_1[8][0]                     \n","                                                                 lstm_1[8][2]                     \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 12)           780         lstm_1[0][0]                     \n","                                                                 lstm_1[1][0]                     \n","                                                                 lstm_1[2][0]                     \n","                                                                 lstm_1[3][0]                     \n","                                                                 lstm_1[4][0]                     \n","                                                                 lstm_1[5][0]                     \n","                                                                 lstm_1[6][0]                     \n","                                                                 lstm_1[7][0]                     \n","                                                                 lstm_1[8][0]                     \n","                                                                 lstm_1[9][0]                     \n","==================================================================================================\n","Total params: 54,305\n","Trainable params: 54,305\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"deHxUNrP9gQu","colab_type":"code","colab":{}},"source":["opt = Adam(lr= 0.01, clipvalue=0.5)\n","model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'], experimental_run_tf_function=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"by_opLYU9gQz","colab_type":"code","colab":{}},"source":["s0 = np.zeros((m, n_s))\n","c0 = np.zeros((m, n_s))\n","outputs = list(Y.swapaxes(0,1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n1-xOEdH9gQ4","colab_type":"code","outputId":"63bed716-0d9a-4369-9ddf-645895827d75","executionInfo":{"status":"ok","timestamp":1584637454209,"user_tz":-420,"elapsed":124809,"user":{"displayName":"Can Udomcharoenchaikit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIB8FkrZmMx76pFQKcawrImVzazmJLi7rbH86KvA=s64","userId":"04089022953377520706"}},"colab":{"base_uri":"https://localhost:8080/","height":766}},"source":["model.fit([X, s0, c0], outputs, epochs=20, batch_size=120)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 15000 samples\n","Epoch 1/20\n","15000/15000 [==============================] - 14s 902us/sample - loss: 12.4272 - dense_2_loss: 0.5838 - dense_2_1_loss: 0.4696 - dense_2_2_loss: 1.1704 - dense_2_3_loss: 2.2840 - dense_2_4_loss: 0.3750 - dense_2_5_loss: 0.8554 - dense_2_6_loss: 2.3389 - dense_2_7_loss: 0.4112 - dense_2_8_loss: 1.4692 - dense_2_9_loss: 2.4697 - dense_2_accuracy: 0.7747 - dense_2_1_accuracy: 0.8761 - dense_2_2_accuracy: 0.4735 - dense_2_3_accuracy: 0.1718 - dense_2_4_accuracy: 0.9397 - dense_2_5_accuracy: 0.6128 - dense_2_6_accuracy: 0.1521 - dense_2_7_accuracy: 0.9439 - dense_2_8_accuracy: 0.2813 - dense_2_9_accuracy: 0.0982\n","Epoch 2/20\n","15000/15000 [==============================] - 6s 377us/sample - loss: 6.6890 - dense_2_loss: 0.0615 - dense_2_1_loss: 0.0582 - dense_2_2_loss: 0.4171 - dense_2_3_loss: 1.1566 - dense_2_4_loss: 0.0048 - dense_2_5_loss: 0.2695 - dense_2_6_loss: 1.6153 - dense_2_7_loss: 0.0076 - dense_2_8_loss: 0.9648 - dense_2_9_loss: 2.1337 - dense_2_accuracy: 0.9761 - dense_2_1_accuracy: 0.9759 - dense_2_2_accuracy: 0.8418 - dense_2_3_accuracy: 0.5425 - dense_2_4_accuracy: 0.9999 - dense_2_5_accuracy: 0.9003 - dense_2_6_accuracy: 0.3896 - dense_2_7_accuracy: 0.9998 - dense_2_8_accuracy: 0.5850 - dense_2_9_accuracy: 0.2027\n","Epoch 3/20\n","15000/15000 [==============================] - 6s 371us/sample - loss: 3.3613 - dense_2_loss: 0.0097 - dense_2_1_loss: 0.0070 - dense_2_2_loss: 0.2099 - dense_2_3_loss: 0.4645 - dense_2_4_loss: 0.0021 - dense_2_5_loss: 0.1455 - dense_2_6_loss: 1.0691 - dense_2_7_loss: 0.0058 - dense_2_8_loss: 0.2421 - dense_2_9_loss: 1.2057 - dense_2_accuracy: 0.9990 - dense_2_1_accuracy: 0.9991 - dense_2_2_accuracy: 0.9079 - dense_2_3_accuracy: 0.8539 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 0.9439 - dense_2_6_accuracy: 0.6101 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.9217 - dense_2_9_accuracy: 0.5403\n","Epoch 4/20\n","15000/15000 [==============================] - 6s 371us/sample - loss: 0.8280 - dense_2_loss: 0.0039 - dense_2_1_loss: 0.0015 - dense_2_2_loss: 0.1074 - dense_2_3_loss: 0.1020 - dense_2_4_loss: 0.0013 - dense_2_5_loss: 0.0848 - dense_2_6_loss: 0.3256 - dense_2_7_loss: 0.0033 - dense_2_8_loss: 0.0294 - dense_2_9_loss: 0.1689 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 0.9578 - dense_2_3_accuracy: 0.9881 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 0.9663 - dense_2_6_accuracy: 0.9030 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.9967 - dense_2_9_accuracy: 0.9754\n","Epoch 5/20\n","15000/15000 [==============================] - 5s 360us/sample - loss: 0.1733 - dense_2_loss: 0.0024 - dense_2_1_loss: 0.0016 - dense_2_2_loss: 0.0285 - dense_2_3_loss: 0.0327 - dense_2_4_loss: 7.9251e-04 - dense_2_5_loss: 0.0194 - dense_2_6_loss: 0.0558 - dense_2_7_loss: 0.0012 - dense_2_8_loss: 0.0072 - dense_2_9_loss: 0.0238 - dense_2_accuracy: 0.9998 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9950 - dense_2_3_accuracy: 0.9973 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 0.9960 - dense_2_6_accuracy: 0.9927 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 0.9999 - dense_2_9_accuracy: 0.9997\n","Epoch 6/20\n","15000/15000 [==============================] - 6s 368us/sample - loss: 0.0467 - dense_2_loss: 5.8457e-04 - dense_2_1_loss: 1.9434e-04 - dense_2_2_loss: 0.0069 - dense_2_3_loss: 0.0094 - dense_2_4_loss: 3.6461e-04 - dense_2_5_loss: 0.0036 - dense_2_6_loss: 0.0135 - dense_2_7_loss: 6.4150e-04 - dense_2_8_loss: 0.0030 - dense_2_9_loss: 0.0087 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 1.0000 - dense_2_3_accuracy: 1.0000 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 0.9999 - dense_2_6_accuracy: 0.9999 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 1.0000 - dense_2_9_accuracy: 1.0000\n","Epoch 7/20\n","15000/15000 [==============================] - 6s 384us/sample - loss: 0.0241 - dense_2_loss: 3.7808e-04 - dense_2_1_loss: 1.2441e-04 - dense_2_2_loss: 0.0032 - dense_2_3_loss: 0.0054 - dense_2_4_loss: 2.4162e-04 - dense_2_5_loss: 0.0016 - dense_2_6_loss: 0.0063 - dense_2_7_loss: 3.8751e-04 - dense_2_8_loss: 0.0018 - dense_2_9_loss: 0.0046 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 1.0000 - dense_2_3_accuracy: 1.0000 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 1.0000 - dense_2_6_accuracy: 1.0000 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 1.0000 - dense_2_9_accuracy: 1.0000\n","Epoch 8/20\n","15000/15000 [==============================] - 5s 365us/sample - loss: 0.0157 - dense_2_loss: 2.6121e-04 - dense_2_1_loss: 8.9375e-05 - dense_2_2_loss: 0.0021 - dense_2_3_loss: 0.0036 - dense_2_4_loss: 1.8409e-04 - dense_2_5_loss: 8.8387e-04 - dense_2_6_loss: 0.0040 - dense_2_7_loss: 2.7633e-04 - dense_2_8_loss: 0.0012 - dense_2_9_loss: 0.0030 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 1.0000 - dense_2_3_accuracy: 1.0000 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 1.0000 - dense_2_6_accuracy: 1.0000 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 1.0000 - dense_2_9_accuracy: 1.0000\n","Epoch 9/20\n","15000/15000 [==============================] - 6s 373us/sample - loss: 0.0113 - dense_2_loss: 1.9515e-04 - dense_2_1_loss: 6.5911e-05 - dense_2_2_loss: 0.0015 - dense_2_3_loss: 0.0026 - dense_2_4_loss: 1.4123e-04 - dense_2_5_loss: 6.4292e-04 - dense_2_6_loss: 0.0029 - dense_2_7_loss: 2.0651e-04 - dense_2_8_loss: 9.2557e-04 - dense_2_9_loss: 0.0022 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 1.0000 - dense_2_3_accuracy: 1.0000 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 1.0000 - dense_2_6_accuracy: 1.0000 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 1.0000 - dense_2_9_accuracy: 1.0000\n","Epoch 10/20\n","15000/15000 [==============================] - 6s 398us/sample - loss: 0.0086 - dense_2_loss: 1.5506e-04 - dense_2_1_loss: 5.2282e-05 - dense_2_2_loss: 0.0011 - dense_2_3_loss: 0.0020 - dense_2_4_loss: 1.1640e-04 - dense_2_5_loss: 4.6413e-04 - dense_2_6_loss: 0.0022 - dense_2_7_loss: 1.6267e-04 - dense_2_8_loss: 7.1117e-04 - dense_2_9_loss: 0.0016 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 1.0000 - dense_2_3_accuracy: 1.0000 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 1.0000 - dense_2_6_accuracy: 1.0000 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 1.0000 - dense_2_9_accuracy: 1.0000\n","Epoch 11/20\n","15000/15000 [==============================] - 6s 383us/sample - loss: 0.0068 - dense_2_loss: 1.2576e-04 - dense_2_1_loss: 4.2031e-05 - dense_2_2_loss: 8.9404e-04 - dense_2_3_loss: 0.0016 - dense_2_4_loss: 9.1637e-05 - dense_2_5_loss: 3.6267e-04 - dense_2_6_loss: 0.0017 - dense_2_7_loss: 1.3058e-04 - dense_2_8_loss: 5.8191e-04 - dense_2_9_loss: 0.0013 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 1.0000 - dense_2_3_accuracy: 1.0000 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 1.0000 - dense_2_6_accuracy: 1.0000 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 1.0000 - dense_2_9_accuracy: 1.0000\n","Epoch 12/20\n","15000/15000 [==============================] - 6s 367us/sample - loss: 0.0055 - dense_2_loss: 1.0510e-04 - dense_2_1_loss: 3.5649e-05 - dense_2_2_loss: 7.2387e-04 - dense_2_3_loss: 0.0013 - dense_2_4_loss: 7.7278e-05 - dense_2_5_loss: 2.8679e-04 - dense_2_6_loss: 0.0014 - dense_2_7_loss: 1.0914e-04 - dense_2_8_loss: 4.8296e-04 - dense_2_9_loss: 0.0010 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 1.0000 - dense_2_3_accuracy: 1.0000 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 1.0000 - dense_2_6_accuracy: 1.0000 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 1.0000 - dense_2_9_accuracy: 1.0000\n","Epoch 13/20\n","15000/15000 [==============================] - 5s 358us/sample - loss: 0.0046 - dense_2_loss: 8.8023e-05 - dense_2_1_loss: 3.0147e-05 - dense_2_2_loss: 6.0159e-04 - dense_2_3_loss: 0.0011 - dense_2_4_loss: 6.6221e-05 - dense_2_5_loss: 2.3207e-04 - dense_2_6_loss: 0.0011 - dense_2_7_loss: 9.0236e-05 - dense_2_8_loss: 4.0517e-04 - dense_2_9_loss: 8.5949e-04 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 1.0000 - dense_2_3_accuracy: 1.0000 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 1.0000 - dense_2_6_accuracy: 1.0000 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 1.0000 - dense_2_9_accuracy: 1.0000\n","Epoch 14/20\n","15000/15000 [==============================] - 6s 370us/sample - loss: 0.0039 - dense_2_loss: 7.4104e-05 - dense_2_1_loss: 2.6164e-05 - dense_2_2_loss: 5.0407e-04 - dense_2_3_loss: 8.9275e-04 - dense_2_4_loss: 5.8347e-05 - dense_2_5_loss: 1.9572e-04 - dense_2_6_loss: 9.6265e-04 - dense_2_7_loss: 7.7006e-05 - dense_2_8_loss: 3.4420e-04 - dense_2_9_loss: 7.2199e-04 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 1.0000 - dense_2_3_accuracy: 1.0000 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 1.0000 - dense_2_6_accuracy: 1.0000 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 1.0000 - dense_2_9_accuracy: 1.0000\n","Epoch 15/20\n","15000/15000 [==============================] - 5s 353us/sample - loss: 0.0033 - dense_2_loss: 6.4319e-05 - dense_2_1_loss: 2.2785e-05 - dense_2_2_loss: 4.2916e-04 - dense_2_3_loss: 7.5766e-04 - dense_2_4_loss: 5.0862e-05 - dense_2_5_loss: 1.6443e-04 - dense_2_6_loss: 8.1309e-04 - dense_2_7_loss: 6.6812e-05 - dense_2_8_loss: 2.9676e-04 - dense_2_9_loss: 6.1173e-04 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 1.0000 - dense_2_3_accuracy: 1.0000 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 1.0000 - dense_2_6_accuracy: 1.0000 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 1.0000 - dense_2_9_accuracy: 1.0000\n","Epoch 16/20\n","15000/15000 [==============================] - 5s 339us/sample - loss: 0.0028 - dense_2_loss: 5.6222e-05 - dense_2_1_loss: 2.0048e-05 - dense_2_2_loss: 3.6921e-04 - dense_2_3_loss: 6.5143e-04 - dense_2_4_loss: 4.4311e-05 - dense_2_5_loss: 1.3874e-04 - dense_2_6_loss: 7.0051e-04 - dense_2_7_loss: 5.8406e-05 - dense_2_8_loss: 2.5842e-04 - dense_2_9_loss: 5.2816e-04 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 1.0000 - dense_2_3_accuracy: 1.0000 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 1.0000 - dense_2_6_accuracy: 1.0000 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 1.0000 - dense_2_9_accuracy: 1.0000\n","Epoch 17/20\n","15000/15000 [==============================] - 6s 381us/sample - loss: 0.0025 - dense_2_loss: 4.9489e-05 - dense_2_1_loss: 1.7901e-05 - dense_2_2_loss: 3.2194e-04 - dense_2_3_loss: 5.6113e-04 - dense_2_4_loss: 3.9581e-05 - dense_2_5_loss: 1.2354e-04 - dense_2_6_loss: 6.1089e-04 - dense_2_7_loss: 5.0887e-05 - dense_2_8_loss: 2.2627e-04 - dense_2_9_loss: 4.5328e-04 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 1.0000 - dense_2_3_accuracy: 1.0000 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 1.0000 - dense_2_6_accuracy: 1.0000 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 1.0000 - dense_2_9_accuracy: 1.0000\n","Epoch 18/20\n","15000/15000 [==============================] - 6s 376us/sample - loss: 0.0021 - dense_2_loss: 4.3471e-05 - dense_2_1_loss: 1.6173e-05 - dense_2_2_loss: 2.8216e-04 - dense_2_3_loss: 4.9150e-04 - dense_2_4_loss: 3.5573e-05 - dense_2_5_loss: 1.0575e-04 - dense_2_6_loss: 5.2897e-04 - dense_2_7_loss: 4.4808e-05 - dense_2_8_loss: 1.9929e-04 - dense_2_9_loss: 3.9698e-04 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 1.0000 - dense_2_3_accuracy: 1.0000 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 1.0000 - dense_2_6_accuracy: 1.0000 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 1.0000 - dense_2_9_accuracy: 1.0000\n","Epoch 19/20\n","15000/15000 [==============================] - 5s 352us/sample - loss: 0.0019 - dense_2_loss: 3.8421e-05 - dense_2_1_loss: 1.4383e-05 - dense_2_2_loss: 2.4899e-04 - dense_2_3_loss: 4.3090e-04 - dense_2_4_loss: 3.2279e-05 - dense_2_5_loss: 9.2138e-05 - dense_2_6_loss: 4.6883e-04 - dense_2_7_loss: 3.9793e-05 - dense_2_8_loss: 1.7779e-04 - dense_2_9_loss: 3.4913e-04 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 1.0000 - dense_2_3_accuracy: 1.0000 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 1.0000 - dense_2_6_accuracy: 1.0000 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 1.0000 - dense_2_9_accuracy: 1.0000\n","Epoch 20/20\n","15000/15000 [==============================] - 6s 377us/sample - loss: 0.0017 - dense_2_loss: 3.3987e-05 - dense_2_1_loss: 1.2897e-05 - dense_2_2_loss: 2.2116e-04 - dense_2_3_loss: 3.8057e-04 - dense_2_4_loss: 2.9019e-05 - dense_2_5_loss: 8.0724e-05 - dense_2_6_loss: 4.1265e-04 - dense_2_7_loss: 3.5724e-05 - dense_2_8_loss: 1.5805e-04 - dense_2_9_loss: 3.0836e-04 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 1.0000 - dense_2_3_accuracy: 1.0000 - dense_2_4_accuracy: 1.0000 - dense_2_5_accuracy: 1.0000 - dense_2_6_accuracy: 1.0000 - dense_2_7_accuracy: 1.0000 - dense_2_8_accuracy: 1.0000 - dense_2_9_accuracy: 1.0000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f1e5e3b37f0>"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"ePf2CDQb9gQ-","colab_type":"text"},"source":["# Let's do some \"translation\""]},{"cell_type":"code","metadata":{"id":"UJdBoaJE9gRA","colab_type":"code","outputId":"c8eb4175-f088-4b52-f19e-7b143faf74f5","executionInfo":{"status":"ok","timestamp":1584637455747,"user_tz":-420,"elapsed":124213,"user":{"displayName":"Can Udomcharoenchaikit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIB8FkrZmMx76pFQKcawrImVzazmJLi7rbH86KvA=s64","userId":"04089022953377520706"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["def prep_input(input_list):\n","    X = []\n","    for line in input_list:\n","        temp=[]\n","        for char in line:\n","            temp.append(char_to_ix[char])\n","        X.append(temp)\n","    X = pad_sequences(X,maxlen=maxlen)\n","    X= to_categorical(X,vocab_size)\n","    X=X.reshape(len(input_list),maxlen ,vocab_size)\n","    \n","    return X\n","\n","EXAMPLES = ['3 May 1999', '05 October 2009', '30 August 2016', '11 July 2000', 'Saturday 19 May 2018', '3 March 2001', '1 March 2001']\n","s0 = np.zeros((len(EXAMPLES), n_s))\n","c0 = np.zeros((len(EXAMPLES), n_s))\n","EXAMPLES = prep_input(EXAMPLES)\n","\n","prediction = model.predict([EXAMPLES , s0, c0])\n","prediction = np.swapaxes(prediction,0,1)\n","prediction = np.argmax(prediction, axis = -1)\n","\n","for j in range(len(prediction)):\n","    output = \"\".join([ix_to_output_char[int(i)] for i in prediction[j]])\n","    print(output)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1999-05-33\n","2009-10-05\n","2016-08-30\n","2000-07-11\n","2018-05-19\n","2001-03-23\n","2001-03-12\n"],"name":"stdout"}]}]}